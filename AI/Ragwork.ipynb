{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "\n",
    "# Initialize MistralAI model\n",
    "llm = ChatMistralAI(model=\"mistral-large-latest\", temperature=0, api_key=\"APIKEY\")\n",
    "\n",
    "# Initialize Sentence Transformer for embedding\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Directory for uploaded lecture notes\n",
    "os.makedirs(\"lecture_notes\", exist_ok=True)\n",
    "\n",
    "# Helper Function: Extract Text from PDF\n",
    "def extract_text_from_pdf(file_path):\n",
    "    \"\"\"Extracts text from the given PDF file.\"\"\"\n",
    "    reader = PdfReader(file_path)\n",
    "    text = \" \".join(page.extract_text() for page in reader.pages if page.extract_text())\n",
    "    return text\n",
    "\n",
    "# Helper Function: Create FAISS Index\n",
    "def create_faiss_index(texts, embedding_model):\n",
    "    \"\"\"Creates a FAISS index for the provided texts.\"\"\"\n",
    "    embeddings = embedding_model.encode(texts, convert_to_tensor=False)\n",
    "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "    index.add(np.array(embeddings))\n",
    "    return index, embeddings\n",
    "\n",
    "# Helper Function: Retrieve Relevant Contexts\n",
    "def retrieve_context(question, texts, index, embedding_model, top_k=3):\n",
    "    \"\"\"Retrieves the top-k relevant contexts for a given question.\"\"\"\n",
    "    question_embedding = embedding_model.encode([question], convert_to_tensor=False)\n",
    "    distances, indices = index.search(np.array(question_embedding), top_k)\n",
    "    relevant_texts = [texts[i] for i in indices[0]]\n",
    "    return relevant_texts\n",
    "\n",
    "# Upload and Process PDF\n",
    "def process_lecture_pdf(pdf_path):\n",
    "    \"\"\"Processes a PDF, extracts text, and builds a FAISS index.\"\"\"\n",
    "    # Extract text from the uploaded PDF\n",
    "    extracted_text = extract_text_from_pdf(pdf_path)\n",
    "    if not extracted_text:\n",
    "        raise ValueError(\"No text could be extracted from the PDF.\")\n",
    "\n",
    "    # Split text into smaller chunks\n",
    "    chunk_size = 300\n",
    "    texts = [extracted_text[i:i + chunk_size] for i in range(0, len(extracted_text), chunk_size)]\n",
    "\n",
    "    # Create a FAISS index\n",
    "    index, embeddings = create_faiss_index(texts, embedding_model)\n",
    "    return texts, index\n",
    "\n",
    "# Function to detect AI-generated content\n",
    "def detect_ai_generated_content(text):\n",
    "    \"\"\"Uses the LLM to detect if the text is likely AI-generated.\"\"\"\n",
    "    system_message = SystemMessage(\n",
    "        content=\"You are an expert in detecting AI-generated content. Analyze the following text and determine if it is likely generated by an AI. Provide a brief explanation.\"\n",
    "    )\n",
    "    user_message = HumanMessage(content=text)\n",
    "    response = llm([system_message, user_message])\n",
    "    return response.content\n",
    "\n",
    "# Answer Evaluation with RAG\n",
    "def evaluate_answer_with_rag(question, student_answer, texts, index):\n",
    "    \"\"\"Evaluates an answer by retrieving relevant contexts and generating feedback.\"\"\"\n",
    "    # Retrieve relevant contexts\n",
    "    relevant_contexts = retrieve_context(question, texts, index, embedding_model)\n",
    "    combined_context = \" \".join(relevant_contexts)\n",
    "\n",
    "    # Define system prompt\n",
    "    trait_definitions = (\n",
    "        \"You are an expert evaluator. Evaluate the student's answer based on the following traits:\\n\"\n",
    "        \"1. **Content**: Relevance and accuracy of the information with relevant context present in notes.\\n\"\n",
    "        \"2. **Coherence**: Logical flow and organization.\\n\"\n",
    "        \"3. **Vocabulary**: Range and appropriateness of vocabulary.\\n\"\n",
    "        \"4. **Grammar**: Correctness of language usage.\\n\\n\"\n",
    "        \"Provide detailed feedback on the answer's performance. At least 1000 words. Calculate overall score out of 10, giving 50% weightage to content and 25% to coherence.\"\n",
    "    )\n",
    "\n",
    "    system_message = SystemMessage(\n",
    "        content=f\"Use the following context to evaluate the student's answer:\\n\\n{combined_context}\\n\\n{trait_definitions}\"\n",
    "    )\n",
    "\n",
    "    user_message = HumanMessage(content=f\"Question: {question}\\nAnswer: {student_answer}\")\n",
    "\n",
    "    # Use MistralAI to generate feedback\n",
    "    response = llm([system_message, user_message])\n",
    "    feedback = response.content\n",
    "\n",
    "    # Detect if the answer is AI-generated\n",
    "    ai_detection_result = detect_ai_generated_content(student_answer)\n",
    "    feedback += f\"\\n\\nAI Detection Result:\\n{ai_detection_result}\"\n",
    "\n",
    "    return feedback\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Input the PDF file name\n",
    "    pdf_file = \"lecture.pdf\"\n",
    "\n",
    "    # Process the lecture PDF\n",
    "    print(\"Processing PDF...\")\n",
    "    texts, faiss_index = process_lecture_pdf(pdf_file)\n",
    "    print(\"PDF processed and FAISS index created.\")\n",
    "\n",
    "    # Example question and student's answer\n",
    "    question = input(\"Enter a question: \")\n",
    "    student_answer = input(\"Enter the student's answer: \")\n",
    "\n",
    "    # Generate feedback\n",
    "    print(\"\\nEvaluating the answer...\")\n",
    "    feedback = evaluate_answer_with_rag(question, student_answer, texts, faiss_index)\n",
    "    print(\"\\nFeedback:\")\n",
    "    print(feedback)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
